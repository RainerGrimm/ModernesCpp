<div class="vorspann">Nach dem Blick auf die parallelen Algorithmen der STL steht diesmal ein Performanztest mit dem Microsoft Compiler und dem GCC Compiler an.<br></div><div class="text">In meinem letzten Artikel "<a title="Link auf https://heise.de/-6140991" alt="%7B%22type%22%3A%22E%22%2C%22subject%22%3A%22%22%2C%22href%22%3A%22https%3A%2F%2Fheise.de%2F-6140991%22%2C%22target%22%3A%22_blank%22%2C%22version%22%3A1%2C%22ir_link%22%3A1%2C%22mediasync_id%22%3A%22%22%2C%22text%22%3A%22Parallele%20Algorithmen%20der%20STL%20mit%20dem%20GCC-Compiler%22%2C%22custom%22%3A%7B%7D%2C%22anchor%22%3A%22%22%2C%22user_params%22%3A%22%22%2C%22alias%22%3A%22%22%2C%22destination%22%3A%22https%3A%2F%2Fheise.de%2F-6140991%22%7D" href="https://heise.de/-6140991">Parallele Algorithmen der STL mit dem GCC-Compiler</a>" habe ich die notwendige Theorie über den C++17 Algorithmus vorgestellt. Heute soll ein Performanztest mit dem Microsoft Compiler und dem GCC Compiler die einfache Frage beantworten: Zahlt sich die Execution Policy aus?</div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//3/1/4/4/1/2/2/TN_214246617_b1a59bd726.png" title="<ir_inline itemname=bilder_mvp_bild_var2:1 type=2>" style="max-height: 25px; max-width: 25px;"><br></div><div class="text">Der Grund für den kurzen Umweg von meinen Template-Artikeln ist, dass ich festgestellt habe, dass GCC mein Lieblingsfeature des C++17 Standards unterstützt: die parallelen Algorithmen der Standard Template Library. Ich verwende in diesem Artikel den brandneuen GCC 11.1, aber ein GCC 9 sollte auch in Ordnung sein. Um die parallelen STL-Algorithmen mit dem GCC zu nutzen, muss eine zusätzliche Bibliothek installiert werden.</div><div class="ztitel">Threading Building Blocks <br> </div><div class="text">Der GCC benutzt unter der Haube die <a title="Link auf https://en.wikipedia.org/wiki/Threading_Building_Blocks" alt="%7B%22href%22%3A%22https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FThreading_Building_Blocks%22%2C%22target%22%3A%22_blank%22%2C%22version%22%3A1%2C%22type%22%3A%22E%22%2C%22subject%22%3A%22%22%2C%22text%22%3A%22Intels%20Thread%20Building%20Blocks%20%28TBB%29%22%2C%22mediasync_id%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22ir_link%22%3A1%2C%22anchor%22%3A%22%22%2C%22destination%22%3A%22https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FThreading_Building_Blocks%22%2C%22user_params%22%3A%22%22%2C%22alias%22%3A%22%22%7D" href="https://en.wikipedia.org/wiki/Threading_Building_Blocks">Intels Thread Building Blocks (TBB)</a>, eine C++ Template-Bibliothek, die von Intel für die parallele Programmierung auf Multicore-Prozessoren entwickelt wurde.</div><div class="text">Um genau zu sein, ist TBB in der Version 2018 oder höher notwendig. Als ich das Entwicklerpaket der TBB auf meinem Linux-Desktop (<a title="Link auf https://www.suse.com/" alt="%7B%22href%22%3A%22https%3A%2F%2Fwww.suse.com%2F%22%2C%22version%22%3A1%2C%22target%22%3A%22_blank%22%2C%22type%22%3A%22E%22%2C%22subject%22%3A%22%22%2C%22text%22%3A%22Suse%22%2C%22mediasync_id%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22ir_link%22%3A1%2C%22anchor%22%3A%22%22%2C%22destination%22%3A%22https%3A%2F%2Fwww.suse.com%2F%22%2C%22user_params%22%3A%22%22%2C%22alias%22%3A%22%22%7D" href="https://www.suse.com/">Suse</a>) installiert habe, wählt der Paketmanager auch den TBB Memory Allocator aus. Die Verwendung der TBB ist einfach. Dem Linker muss lediglich TBB mit dem Flag<span class="tx_code"> -ltbb</span> bekannt gemacht werden.<br></div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//3/1/4/4/1/2/2/TN_214246620_cd4d4f91da.png" title="<ir_inline itemname=bilder_mvp_bild_var2:3 type=2>" style="max-height: 25px; max-width: 25px;"><br></div><div class="text">Nun bin ich bereit, meine nächsten Schritte mit den parallelen Algorithmen durchzuführen. Hier sind die ersten Zahlen unter Verwendung des Microsoft Compilers 19.16 und des GCC 11.1.</div><div class="ztitel">Performance-Zahlen mit dem Microsoft Compiler und dem GCC Compiler</div><div class="text">Das folgende Programm <span class="tx_code">parallelSTLPerformance.cpp</span> berechnet die Tangens mit der sequentiellen (1), parallelen (2) und parallelen und vektorisierten (3) Execution Policy.</div><div class="pre">// parallelSTLPerformance.cpp<br><br>#include &lt;algorithm&gt;<br>#include &lt;cmath&gt;<br>#include &lt;chrono&gt;<br>#include &lt;execution&gt;<br>#include &lt;iostream&gt;<br>#include &lt;random&gt;<br>#include &lt;string&gt;<br>#include &lt;vector&gt;<br><br>constexpr long long size = 500'000'000; &nbsp;<br>&nbsp; <br>const double pi = std::acos(-1);<br><br>template &lt;typename Func&gt;<br>void getExecutionTime(const std::string&amp; title, Func func){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (4)<br>&nbsp;&nbsp; &nbsp;<br>&nbsp; const auto sta = std::chrono::steady_clock::now();<br>&nbsp; func();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (5)<br>&nbsp; const std::chrono::duration&lt;double&gt; dur = std::chrono::steady_clock::now()<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - sta;<br>&nbsp; std::cout &lt;&lt; title &lt;&lt; ": " &lt;&lt; dur.count() &lt;&lt; " sec. " &lt;&lt; std::endl;<br>&nbsp;&nbsp;&nbsp; &nbsp;<br>}<br>&nbsp;&nbsp; &nbsp;<br>int main(){<br><br>&nbsp; std::cout &lt;&lt; '\n';<br>&nbsp;&nbsp; &nbsp;<br>&nbsp; std::vector&lt;double&gt; randValues;<br>&nbsp; randValues.reserve(size);<br>&nbsp; &nbsp;<br>&nbsp; std::mt19937 engine;<br>&nbsp; std::uniform_real_distribution&lt;&gt; uniformDist(0, pi / 2);<br>&nbsp; for (long long i = 0 ; i &lt; size ; ++i) {<br>&nbsp;&nbsp;&nbsp; randValues.push_back(uniformDist(engine));<br>&nbsp; }<br>&nbsp;&nbsp; &nbsp;<br>&nbsp; std::vector&lt;double&gt; workVec(randValues);<br>&nbsp;&nbsp; &nbsp;<br>&nbsp; getExecutionTime("std::execution::seq", [workVec]() mutable {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (6)<br>&nbsp;&nbsp;&nbsp; std::transform(std::execution::seq, workVec.begin(), workVec.end(),// (1)<br>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; workVec.begin(), <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [](double arg){ return std::tan(arg); }&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; );<br>&nbsp;&nbsp;&nbsp; });<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br>&nbsp; getExecutionTime("std::execution::par", [workVec]() mutable {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (7)<br>&nbsp;&nbsp;&nbsp; std::transform(std::execution::par, workVec.begin(), workVec.end(),// (2)<br>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; workVec.begin(), <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [](double arg){ return std::tan(arg); }<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; );<br>&nbsp; });<br>&nbsp;&nbsp;&nbsp; &nbsp;<br>&nbsp; getExecutionTime("std::execution::par_unseq", [workVec]() mutable {&nbsp; // (8)<br>&nbsp;&nbsp;&nbsp; std::transform(std::execution::par_unseq,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (3)<br>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; workVec.begin(), workVec.end(), &nbsp;<br>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; workVec.begin(), <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [](double arg){ return std::tan(arg); }<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; );<br>&nbsp; });<br><br>&nbsp; std::cout &lt;&lt; '\n';<br>&nbsp;&nbsp; &nbsp;<br>}</div><div class="text">Zunächst wird der Vektor <span class="tx_code">randValues</span> mit 500 Millionen Zahlen aus dem halboffenen Intervall<span class="tx_code"> [0, pi / 2 [</span> gefüllt. Das Funktions-Template <span class="tx_code">getExecutionTime</span> (4) erhält den Namen der Execution Policy und die Lambda-Funktion und führt die Lambda-Funktion (5) aus. Zum Abschluss wird die Ausführungszeit dargestellt. Es gibt eine Besonderheit bei den drei Lambda-Ausdrücken ((6), (7) und (8)), die in diesem Programm verwendet werden. Sie sind als <span class="tx_code">mutable</span> deklariert. Das ist notwendig, weil die Lambda-Audrücke ihr Argument <span class="tx_code">workVec</span> verändern. Lambda-Ausdrücke sind per Default konstant. Wenn er seinen Werte ändern will, muss er als <span class="tx_code">mutable</span> deklariert werden.</div><div class="ztitel_kleiner">Disclaimer</div><div class="text">Ich betone ausdrücklich, dass ich nicht Windows und Linux miteinander vergleichen, da beide Computer, auf denen Windows oder Linux verwendet werden, unterschiedliche Leistungscharakteristiken besitzen. Diese Performanzzahlen sollen nur ein Bauchgefühl geben. Wer die Zahlen für das eigene System kennen will, mus den Test wiederholen.</div><div class="text">Ich benutze die maximale Optimierung auf Windows und Linux. Das bedeutet unter Windows kommt das Flag <span class="tx_code">/O2</span> und unter Linux das Flag<span class="tx_code"> -O3</span> zum Einsatz.</div><div class="text">Um es kurz zu machen: Mir geht es darum, ob und in welchem Umfang sich die parallele Ausführung der STL-Algorithmen auszahlt. Mein Hauptaugenmerk liegt dabei auf den relativen Performanzunterschieden der sequentiellen und parallelen Ausführung.</div><div class="ztitel_kleiner">Windows</div><div class="text">Mein Windows-Rechner hat acht logische Kerne, aber die parallele Ausführung ist mehr als zehnmal schneller.</div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//3/1/4/4/1/2/2/TN_214246626_a4da13e640.png" title="<ir_inline itemname=bilder_mvp_bild_var2:4 type=2>" style="max-height: 25px; max-width: 25px;"><br></div><div class="text">Die Zahlen für die parallele und die parallele und vektorisierte Ausführung liegen in der gleichen Größenordnung. Hier ist die Erklärung dazu von dem <a title="Link auf https://devblogs.microsoft.com/cppblog/using-c17-parallel-algorithms-for-better-performance/" alt="%7B%22anchor%22%3A%22%22%2C%22destination%22%3A%22https%3A%2F%2Fdevblogs.microsoft.com%2Fcppblog%2Fusing-c17-parallel-algorithms-for-better-performance%2F%22%2C%22alias%22%3A%22%22%2C%22user_params%22%3A%22%22%2C%22version%22%3A1%2C%22target%22%3A%22_blank%22%2C%22href%22%3A%22https%3A%2F%2Fdevblogs.microsoft.com%2Fcppblog%2Fusing-c17-parallel-algorithms-for-better-performance%2F%22%2C%22subject%22%3A%22%22%2C%22type%22%3A%22E%22%2C%22custom%22%3A%7B%7D%2C%22text%22%3A%22Visual%20C%2B%2B%20Team%20Blog%22%2C%22mediasync_id%22%3A%22%22%2C%22ir_link%22%3A1%7D" href="https://devblogs.microsoft.com/cppblog/using-c17-parallel-algorithms-for-better-performance/">Visual C++ Team Blog</a>: <i>Using C++17 Parallel Algorithms for Better Performance: Note that the Visual C++ implementation implements the parallel and parallel unsequenced policies the same way, so you should not expect better performance for using par_unseq on our implementation, but implementations may exist that can use that additional freedom someday.</i></div><div class="ztitel_kleiner">Linux<br></div><div class="text">Mein Linux-Rechner besitzt nur vier Kerne. Hier sind die Zahlen.</div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//3/1/4/4/1/2/2/TN_214246632_b89045b9e9.png" title="<ir_inline itemname=bilder_mvp_bild_var2:5 type=2>" style="max-height: 25px; max-width: 25px;"><br></div><div class="text">Die Zahlen verhalten sich erwartungsgemäß. Ich habe vier Kerne, und die parallele Ausführung ist etwa viermal so schnell wie die sequentielle Ausführung. Die Leistungszahlen der parallelen und vektorisierten Version und der parallelen Version liegen in der gleichen Größenordnung. Meine Vermutung ist natürlich, dass der GCC-Compiler die gleiche Strategie wie der Windows-Compiler verwendet. Wenn ich nach der parallelen und vektorisierten Ausführung frage, indem ich die Ausführungsrichtlinie<span class="tx_code"> std::execute::par_unseq</span> verwende, bekomme ich die parallele Execution Policy (<span class="tx_code">std::execute::par</span>). Dieses Verhalten entspricht dem C++17 Standard, da die Execution Policy nur eine Empfehlung für den Compiler ist.</div><div class="text">Meines Wissens unterstützt weder der Windows-Compiler noch der GCC-Compiler die parallele und vektorisierte Ausführung der parallelen STL-Algorithmen. Um die parallelen und vektorisierten Algorithmen in Aktion zu sehen, könnte Nvidias STL-Implementierung <a title="Link auf https://docs.nvidia.com/cuda/thrust/index.html" alt="%7B%22destination%22%3A%22https%3A%2F%2Fdocs.nvidia.com%2Fcuda%2Fthrust%2Findex.html%22%2C%22user_params%22%3A%22%22%2C%22alias%22%3A%22%22%2C%22anchor%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22text%22%3A%22Thrust%22%2C%22mediasync_id%22%3A%22%22%2C%22ir_link%22%3A1%2C%22version%22%3A1%2C%22target%22%3A%22_blank%22%2C%22href%22%3A%22https%3A%2F%2Fdocs.nvidia.com%2Fcuda%2Fthrust%2Findex.html%22%2C%22subject%22%3A%22%22%2C%22type%22%3A%22E%22%7D" href="https://docs.nvidia.com/cuda/thrust/index.html">Thrust</a> ein idealer Kandidat sein. Für weitere Informationen möchte ich auf den Nvidi- Beitrag <a title="Link auf https://developer.nvidia.com/blog/accelerating-standard-c-with-gpus-using-stdpar/" alt="%7B%22user_params%22%3A%22%22%2C%22alias%22%3A%22%22%2C%22destination%22%3A%22https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Faccelerating-standard-c-with-gpus-using-stdpar%2F%22%2C%22anchor%22%3A%22%22%2C%22ir_link%22%3A1%2C%22custom%22%3A%7B%7D%2C%22mediasync_id%22%3A%22%22%2C%22text%22%3A%22%5C%22C%2B%2B%20Standard%20Parallelism%22%2C%22type%22%3A%22E%22%2C%22subject%22%3A%22%22%2C%22target%22%3A%22_blank%22%2C%22version%22%3A1%2C%22href%22%3A%22https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Faccelerating-standard-c-with-gpus-using-stdpar%2F%22%7D" href="https://developer.nvidia.com/blog/accelerating-standard-c-with-gpus-using-stdpar/">"C++ Standard Parallelism</a>" verweisen.</div><div class="ztitel">Wie geht's weiter?</div><div class="text">Nach diesem C++17 Abstecher gehe ich zurück auf meinen ursprünglichen Pfad: Templates. In meinem nächsten Post tauche ich tiefer in Templates ein und schreibe über die Template-Instanziierung.</div>